# 优雅的使用Redis（三）——调优与运维

一个系统开发是它生命周期的一部分，运行维护也是它的一部分。有时候随着业务的发展和迁移，需要对系统进行重构，原有的数据结构可能并不是符合现在的业务场景的最佳选择，此外很多开发测试过程，我们的测试用例并不能模拟出线上的真实环境，会遇到很多问题，导致服务不可用等等。因此，我们可能需要从代码和运维上做一些调整。

## 调优

这里说的调优是指我们在优化我们和Redis交互的代码。因为我熟悉Jedis（Java中一种Redis客户端），例子均是在Jedis上的。

+ **减少key的长度**

在我们量化分析时候，能够拿到Redis的内存使用详细信息。我们可以知道指定Key在Redis中实际存储需要的存储空间，对于长的key来说，必然占据的内存空间大，对于命名不规范或者较长的进行调整，避免太长的key浪费内存。

+ **读写分离**

从量化分析的csv，我们可以得到哪些数据读、写比较频繁。对于读写频繁的数据做读写分离能够提高Redis的效率（速度）

+ **选择批处理操作**

很多时候，我们可能一次业务流程下需要执行多个Redis命令，如果每次一个一个执行，需要占用多个连接。对于这样的场景，我们尽量通过hmget、hset等这样的批处理命令，或者使用管道（pipeline），将多个命令放入到管道中，在一次Redis的client和Server交互中将所有的操作传输过去，节省命令。

+ **使用Lua脚本时间简单逻辑或批处理**

有些业务的操作可能很简单，但是这样操作很多，但是没有满足需求的批处理命令，管道也不支持，可能需要做一个简单计算或者判断。对于这样的场景，我们可以使用Lua脚本来实现。现在Redis是支持Lua执行引擎的。

+ **不对key和field做模式匹配**

Redis是一种Nosql的数据库，不能把关系型数据库的模型和逻辑硬搬过去。在Nosql中，为了得到更好的查询效果会将数据冗余存储。在Redis不要去做类似SQL中like操作，还有不要对key和field进行模式匹配，因为key模式匹配是扫描所有的key，这样会造成Redis的cup飙升，如果需要做like操作，请选择全文检索中间件，如Solr或者ElasticSearch。

## 运维

### 造成内存翻倍的原因

1.	Redis在执行bgsave时，会fork一个子进程，通过子进程将内存中的数据写入硬盘中，这个时候内存可能会翻倍。
2. Redis默认使用jemalloc分配内存，当遇到变长key-value负载时，会出现碎片问题：内存利用率低，实际分配的内存比所需要的内存多。

我们在生产中就到过这些问题，当时是卡片业务的服务，master节点内存是8G左右，slave内存占用了14G（slave服务器总共16G内存），造成数据无法读取，为什么会出现slave比master内存多这么多呢？slave中数据全部是通过master同步过去，而且不能直接写入的。通过分析，我们得知slave中存在大量的内存碎片，造成内存碎片的原因，是我们的一个业务中存储key-value长度变化非常大。

遇到这种情况后，我们先是将slave的host映射到master机器，重启了slave机器，内存立马降下来。

关于内存碎片化，可以[参考博客](http://blog.csdn.net/opennaive/article/details/40587611)

### 一定要定期执行bgsave和预留bgsave需要的内存开销

几个月前，我们一个设备信息存储库（手机的设备信息），因为其他的业务，造成该Redis服务器的大量内存碎片，32G内存占用了29G，无法执行bgsave，也不能做复制同步（replication），查看了上次执行bgsave的时间是4个月前。如果不重启，无法恢复该服务，但是重启又回造成好几月的数据丢失，而且该服务器还没有做主从和读写分离，最后不得不尝试做数据同步复制，在做同步时的时候，因为负载过高直接宕机，丢失了两千多万的用户设备信息。好在是数据库用用户设备信息日志的备份，我们通过程序处理，清洗除了那部分数据，花了几天时间恢复。

对于运维来说，Redis出了日常的监控，还需要经常查看内存碎片化情况，定期执行bgsave，对于非常重要的数据最好多复制存储。公司一个Redis方面的专家告诉我，当服务使用了机器3/4内存了，就必须警惕了，这个时候无论是执行bgsave还是做复制同步都有可能无法完成任务，当内存上升明显的时候，需要提前做好数据的分离，对于不同的业务分开存储。

### 通过slowlog查看慢日志

通过slowlog get 命令查看Redis的慢日志，找出执行耗时的命令，进而针对性分析优化。关于slowlog的信息，请[阅读文档slowlog](https://redis.readthedocs.org/en/latest/server/slowlog.html)

通过分析慢日志信息，我们可以找到我们代码中可以优化的地方，进行优化，从而提高代码的效率。

